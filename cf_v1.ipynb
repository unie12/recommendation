{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlH5A//exYTLlBP+yPhZI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unie12/recommendation/blob/main/cf_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import psutil\n",
        "\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.sparse import csr_matrix, coo_matrix\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import joblib"
      ],
      "metadata": {
        "id": "NRimcRx3JvtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 (청크 단위로 처리)\n",
        "def load_data_in_chunks(file_path, chunk_size=100000):\n",
        "    chunks = []\n",
        "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
        "        chunks.append(chunk)\n",
        "    return pd.concat(chunks, ignore_index=True)"
      ],
      "metadata": {
        "id": "ChOECu_Ns1Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = shuffle(ratings_df, random_state=2021)\n",
        "cutoff = int(TRAIN_SIZE * len(ratings_df))\n",
        "ratings_train = ratings_df.iloc[:cutoff]\n",
        "ratings_test = ratings_df.iloc[cutoff:]"
      ],
      "metadata": {
        "id": "2SisH0L1JxrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메모리 사용량 모니터링 함수\n",
        "def get_memory_usage():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return process.memory_info().rss / 1024 / 1024  # MB 단위로 반환"
      ],
      "metadata": {
        "id": "3sq4Xm16DJPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_data(model_dir='/content'):\n",
        "    model_path = os.path.join(model_dir, 'cf_more_data.pkl')\n",
        "    try:\n",
        "        cf_model = joblib.load(model_path)\n",
        "        print(\"Successfully loaded the model\")\n",
        "\n",
        "        # 로드 후 상태 출력\n",
        "        print(\"Model attributes after loading:\", cf_model.__dict__.keys())\n",
        "\n",
        "        return cf_model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "kdi45owQL9Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import psutil\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.sparse import csr_matrix, coo_matrix\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import joblib\n",
        "\n",
        "# 데이터 로드 (청크 단위로 처리)\n",
        "def load_data_in_chunks(file_path, chunk_size=100000):\n",
        "    chunks = []\n",
        "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
        "        chunks.append(chunk)\n",
        "    return pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "movies_df = load_data_in_chunks('/content/movie.csv')\n",
        "ratings_df = load_data_in_chunks('/content/rating.csv')\n",
        "\n",
        "\n",
        "# 사용자 ID 140000의 평점 데이터 추출\n",
        "user_id_to_include = 140000\n",
        "user_ratings = ratings_df[ratings_df['userId'] == user_id_to_include]\n",
        "\n",
        "\n",
        "movies_df_filtered = movies_df\n",
        "ratings_df_filtered = ratings_df[ratings_df['movieId'].isin(movies_df_filtered['movieId'])]\n",
        "# ratings_df_filtered = pd.concat([ratings_df_filtered, user_ratings]).drop_duplicates()\n",
        "\n",
        "# 사용자 ID 140000의 데이터가 포함되어 있는지 확인\n",
        "print(\"사용자 ID 140000의 데이터:\")\n",
        "print(ratings_df_filtered[ratings_df_filtered['userId'] == 140000])\n",
        "\n",
        "# 필터링 전과 후의 ratings 데이터 크기 출력\n",
        "print(f\"Original ratings size: {len(ratings_df)}\")\n",
        "print(f\"Filtered ratings size: {len(ratings_df_filtered)}\")\n",
        "\n",
        "# 데이터 분할\n",
        "TRAIN_SIZE = 0.75\n",
        "\n",
        "ratings_df_filtered = shuffle(ratings_df_filtered, random_state=2021)\n",
        "cutoff = int(TRAIN_SIZE * len(ratings_df_filtered))\n",
        "ratings_train = ratings_df_filtered.iloc[:cutoff]\n",
        "ratings_test = ratings_df_filtered.iloc[cutoff:]\n",
        "\n",
        "print(\"User 140000 data in training set:\")\n",
        "print(ratings_train[ratings_train['userId'] == 140000])\n",
        "print(\"\\nUser 140000 data in test set:\")\n",
        "print(ratings_test[ratings_test['userId'] == 140000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZAshoBO9rOW",
        "outputId": "b9ce622e-6ffb-41e7-f0fb-f8c0aaf51feb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용자 ID 140000의 데이터:\n",
            "         userId  movieId  rating             timestamp\n",
            "1949366  140000    79132     5.0  2024-10-12 12:00:00 \n",
            "1949367  140000    56782     5.0   2024-10-12 12:00:00\n",
            "1949368  140000    76091     5.0   2024-10-12 12:00:00\n",
            "1949369  140000    61018     5.0   2024-10-12 12:00:00\n",
            "1949370  140000      123     3.5   2024-10-12 12:00:00\n",
            "1949371  140000     5989     4.5   2024-10-12 12:00:00\n",
            "1949372  140000    58559     5.0   2024-10-12 12:00:00\n",
            "1949373  140000      296     5.0  2024-10-12 12:00:00 \n",
            "1949374  140000      306     4.5  2024-10-12 12:00:00 \n",
            "1949375  140000      307     4.0  2024-10-12 12:00:00 \n",
            "1949376  140000      308     4.0  2024-10-12 12:00:00 \n",
            "1949377  140000       16     3.5  2024-10-12 12:00:00 \n",
            "1949378  140000      111     4.0  2024-10-12 12:00:00 \n",
            "1949379  140000     1227     4.0  2024-10-12 12:00:00 \n",
            "1949380  140000      858     4.0  2024-10-12 12:00:00 \n",
            "1949381  140000    48394     3.0  2024-10-12 12:00:00 \n",
            "1949382  140000   111622     4.0  2024-10-12 12:00:00 \n",
            "1949383  140000    72998     4.0  2024-10-12 12:00:00 \n",
            "1949385  140000       56     3.5  2024-10-12 12:00:00 \n",
            "1949386  140000    48774     4.0  2024-10-12 12:00:00 \n",
            "1949387  140000      959     4.5  2024-10-12 12:00:00 \n",
            "1949388  140000      874     2.5  2024-10-12 12:00:00 \n",
            "1949389  140000      147     2.5  2024-10-12 12:00:00 \n",
            "1949390  140000     4959     3.0  2024-10-12 12:00:00 \n",
            "1949391  140000    69134     2.5  2024-10-12 12:00:00 \n",
            "1949392  140000     1172     3.0  2024-10-12 12:00:00 \n",
            "1949393  140000     5388     3.5  2024-10-12 12:00:00 \n",
            "1949394  140000      260     4.0  2024-10-12 12:00:00 \n",
            "1949395  140000      296     4.5  2024-10-12 12:00:00 \n",
            "1949396  140000      527     4.0  2024-10-12 12:00:00 \n",
            "1949397  140000      593     5.0  2024-10-12 12:00:00 \n",
            "1949398  140000      608     5.0  2024-10-12 12:00:00 \n",
            "1949399  140000      858     4.0  2024-10-12 12:00:00 \n",
            "1949400  140000      912     4.0  2024-10-12 12:00:00 \n",
            "1949401  140000     1221     3.0  2024-10-12 12:00:00 \n",
            "1949402  140000     1732     5.0  2024-10-12 12:00:00 \n",
            "1949403  140000     2329     4.5  2024-10-12 12:00:00 \n",
            "1949404  140000     2712     4.0  2024-10-12 12:00:00 \n",
            "1949405  140000     2858     3.5  2024-10-12 12:00:00 \n",
            "1949406  140000     2959     5.0  2024-10-12 12:00:00 \n",
            "1949407  140000     3481     3.0  2024-10-12 12:00:00 \n",
            "1949408  140000     4011     3.5  2024-10-12 12:00:00 \n",
            "1949409  140000     4226     4.5  2024-10-12 12:00:00 \n",
            "1949410  140000     5995     5.0  2024-10-12 12:00:00 \n",
            "1949411  140000     6016     4.5  2024-10-12 12:00:00 \n",
            "1949412  140000     6502     4.0  2024-10-12 12:00:00 \n",
            "1949413  140000     7361     4.5  2024-10-12 12:00:00 \n",
            "1949414  140000    27773     5.0  2024-10-12 12:00:00 \n",
            "1949415  140000    30707     4.0  2024-10-12 12:00:00 \n",
            "1949416  140000    30749     5.0  2024-10-12 12:00:00 \n",
            "1949417  140000    44555     4.5  2024-10-12 12:00:00 \n",
            "1949418  140000    55820     4.5  2024-10-12 12:00:00 \n",
            "1949419  140000   132000     5.0  2024-10-12 12:00:00 \n",
            "1949420  140000   132001     5.0  2024-10-12 12:00:00 \n",
            "Original ratings size: 1949421\n",
            "Filtered ratings size: 1949420\n",
            "User 140000 data in training set:\n",
            "         userId  movieId  rating             timestamp\n",
            "1949368  140000    76091     5.0   2024-10-12 12:00:00\n",
            "1949378  140000      111     4.0  2024-10-12 12:00:00 \n",
            "1949406  140000     2959     5.0  2024-10-12 12:00:00 \n",
            "1949398  140000      608     5.0  2024-10-12 12:00:00 \n",
            "1949401  140000     1221     3.0  2024-10-12 12:00:00 \n",
            "1949410  140000     5995     5.0  2024-10-12 12:00:00 \n",
            "1949387  140000      959     4.5  2024-10-12 12:00:00 \n",
            "1949386  140000    48774     4.0  2024-10-12 12:00:00 \n",
            "1949413  140000     7361     4.5  2024-10-12 12:00:00 \n",
            "1949380  140000      858     4.0  2024-10-12 12:00:00 \n",
            "1949382  140000   111622     4.0  2024-10-12 12:00:00 \n",
            "1949393  140000     5388     3.5  2024-10-12 12:00:00 \n",
            "1949405  140000     2858     3.5  2024-10-12 12:00:00 \n",
            "1949373  140000      296     5.0  2024-10-12 12:00:00 \n",
            "1949374  140000      306     4.5  2024-10-12 12:00:00 \n",
            "1949415  140000    30707     4.0  2024-10-12 12:00:00 \n",
            "1949400  140000      912     4.0  2024-10-12 12:00:00 \n",
            "1949420  140000   132001     5.0  2024-10-12 12:00:00 \n",
            "1949397  140000      593     5.0  2024-10-12 12:00:00 \n",
            "1949404  140000     2712     4.0  2024-10-12 12:00:00 \n",
            "1949375  140000      307     4.0  2024-10-12 12:00:00 \n",
            "1949391  140000    69134     2.5  2024-10-12 12:00:00 \n",
            "1949399  140000      858     4.0  2024-10-12 12:00:00 \n",
            "1949379  140000     1227     4.0  2024-10-12 12:00:00 \n",
            "1949371  140000     5989     4.5   2024-10-12 12:00:00\n",
            "1949388  140000      874     2.5  2024-10-12 12:00:00 \n",
            "1949402  140000     1732     5.0  2024-10-12 12:00:00 \n",
            "1949385  140000       56     3.5  2024-10-12 12:00:00 \n",
            "1949414  140000    27773     5.0  2024-10-12 12:00:00 \n",
            "1949367  140000    56782     5.0   2024-10-12 12:00:00\n",
            "1949408  140000     4011     3.5  2024-10-12 12:00:00 \n",
            "1949416  140000    30749     5.0  2024-10-12 12:00:00 \n",
            "\n",
            "User 140000 data in test set:\n",
            "         userId  movieId  rating             timestamp\n",
            "1949383  140000    72998     4.0  2024-10-12 12:00:00 \n",
            "1949390  140000     4959     3.0  2024-10-12 12:00:00 \n",
            "1949389  140000      147     2.5  2024-10-12 12:00:00 \n",
            "1949417  140000    44555     4.5  2024-10-12 12:00:00 \n",
            "1949370  140000      123     3.5   2024-10-12 12:00:00\n",
            "1949409  140000     4226     4.5  2024-10-12 12:00:00 \n",
            "1949377  140000       16     3.5  2024-10-12 12:00:00 \n",
            "1949407  140000     3481     3.0  2024-10-12 12:00:00 \n",
            "1949403  140000     2329     4.5  2024-10-12 12:00:00 \n",
            "1949372  140000    58559     5.0   2024-10-12 12:00:00\n",
            "1949411  140000     6016     4.5  2024-10-12 12:00:00 \n",
            "1949394  140000      260     4.0  2024-10-12 12:00:00 \n",
            "1949392  140000     1172     3.0  2024-10-12 12:00:00 \n",
            "1949418  140000    55820     4.5  2024-10-12 12:00:00 \n",
            "1949395  140000      296     4.5  2024-10-12 12:00:00 \n",
            "1949381  140000    48394     3.0  2024-10-12 12:00:00 \n",
            "1949366  140000    79132     5.0  2024-10-12 12:00:00 \n",
            "1949396  140000      527     4.0  2024-10-12 12:00:00 \n",
            "1949419  140000   132000     5.0  2024-10-12 12:00:00 \n",
            "1949376  140000      308     4.0  2024-10-12 12:00:00 \n",
            "1949369  140000    61018     5.0   2024-10-12 12:00:00\n",
            "1949412  140000     6502     4.0  2024-10-12 12:00:00 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 메모리 사용량 모니터링 함수\n",
        "def get_memory_usage():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return process.memory_info().rss / 1024 / 1024  # MB 단위로 반환\n",
        "\n",
        "class CollaborativeFiltering:\n",
        "    def __init__(self, ratings_df_filtered, hyper_params):\n",
        "        self.R = ratings_df_filtered\n",
        "        self.num_users = len(np.unique(self.R.row))\n",
        "        self.num_items = len(np.unique(self.R.col))\n",
        "        self.K = hyper_params['K']\n",
        "        self.alpha = hyper_params['alpha']\n",
        "        self.beta = hyper_params['beta']\n",
        "        self.iterations = hyper_params['iterations']\n",
        "        self.verbose = hyper_params['verbose']\n",
        "        self.batch_size = hyper_params['batch_size']\n",
        "        self.b = np.mean(self.R.data)  # 전체 평균 rating 초기화\n",
        "\n",
        "        self._create_mappings()\n",
        "        self.initialize_factors()\n",
        "\n",
        "    def _create_mappings(self):\n",
        "        self.user_id_map = {id: idx for idx, id in enumerate(np.unique(self.R.row))}\n",
        "        self.item_id_map = {id: idx for idx, id in enumerate(np.unique(self.R.col))}\n",
        "        self.idx_user_map = {v: k for k, v in self.user_id_map.items()}\n",
        "        self.idx_item_map = {v: k for k, v in self.item_id_map.items()}\n",
        "\n",
        "    def initialize_factors(self):\n",
        "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)).astype(np.float32)\n",
        "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)).astype(np.float32)\n",
        "        self.b_u = np.zeros(self.num_users, dtype=np.float32)\n",
        "        self.b_d = np.zeros(self.num_items, dtype=np.float32)\n",
        "\n",
        "    def rmse(self):\n",
        "        xs, ys = self.R.nonzero()\n",
        "        predictions = self.get_prediction(xs, ys)\n",
        "        errors = self.R.data - predictions.flatten()\n",
        "        return np.sqrt(np.mean(errors**2))\n",
        "\n",
        "    def get_prediction(self, i, j):\n",
        "        return self.b + self.b_u[i] + self.b_d[j] + np.sum(self.P[i] * self.Q[j], axis=1)\n",
        "\n",
        "    def sgd_batch(self, batch):\n",
        "        i, j, r = zip(*batch)\n",
        "        i, j, r = np.array(i, dtype=int), np.array(j, dtype=int), np.array(r)\n",
        "        prediction = self.get_prediction(i, j)\n",
        "        e = r - prediction\n",
        "\n",
        "        self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
        "        self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
        "\n",
        "        P_i = self.P[i]\n",
        "        Q_j = self.Q[j]\n",
        "\n",
        "        e_reshaped = e.reshape(-1, 1)\n",
        "        self.P[i] += self.alpha * (e_reshaped * Q_j - self.beta * P_i)\n",
        "        self.Q[j] += self.alpha * (e_reshaped * P_i - self.beta * Q_j)\n",
        "\n",
        "    def set_test(self, ratings_test):\n",
        "        test_set = []\n",
        "        for _, row in ratings_test.iterrows():\n",
        "            user = row['userId']\n",
        "            item = row['movieId']\n",
        "            if user in self.user_id_map and item in self.item_id_map:\n",
        "                i, j = self.user_id_map[user], self.item_id_map[item]\n",
        "                test_set.append((i, j, row['rating']))\n",
        "\n",
        "        self.test_set = test_set\n",
        "        return test_set\n",
        "\n",
        "    def test_rmse(self):\n",
        "        test_set = np.array(self.test_set)\n",
        "        predictions = self.get_prediction(test_set[:, 0].astype(int), test_set[:, 1].astype(int))\n",
        "        errors = test_set[:, 2] - predictions\n",
        "        return np.sqrt(np.mean(errors**2))\n",
        "\n",
        "    def train(self):\n",
        "        samples = list(zip(self.R.nonzero()[0], self.R.nonzero()[1], self.R.data))\n",
        "\n",
        "        training_process = []\n",
        "        for i in range(self.iterations):\n",
        "            np.random.shuffle(samples)\n",
        "\n",
        "            for j in range(0, len(samples), self.batch_size):\n",
        "                batch = samples[j:j+self.batch_size]\n",
        "                try:\n",
        "                    self.sgd_batch(batch)\n",
        "                except MemoryError:\n",
        "                    print(\"MemoryError occurred during training. Trying to reduce memory usage...\")\n",
        "                    # 배치 크기 줄이기\n",
        "                    self.batch_size = max(1, self.batch_size // 2)\n",
        "                    continue  # 현재 배치에서 계속 진행\n",
        "\n",
        "                # 중간 결과 삭제\n",
        "                del batch\n",
        "\n",
        "            if self.verbose and (i+1) % 10 == 0:\n",
        "                rmse1 = self.rmse()\n",
        "                rmse2 = self.test_rmse()\n",
        "                training_process.append((i+1, rmse1, rmse2))\n",
        "                print(f'Iteration : {i+1} ; Train RMSE = {rmse1:.4f} ; Test RMSE = {rmse2:.4f}')\n",
        "\n",
        "        return training_process\n",
        "\n",
        "    def predict(self, user_id, item_id):\n",
        "        if user_id in self.user_id_map and item_id in self.item_id_map:\n",
        "            return self.get_prediction(self.user_id_map[user_id], self.item_id_map[item_id])[0]\n",
        "        else:\n",
        "            return self.b  # 평균 평점 반환\n",
        "\n",
        "    def full_prediction(self):\n",
        "        return self.b + self.b_u[:, np.newaxis] + self.b_d[np.newaxis, :] + self.P.dot(self.Q.T)\n",
        "\n",
        "    def predict_for_user(self, user_id):\n",
        "        if user_id in self.user_id_map:\n",
        "            user_idx = self.user_id_map[user_id]\n",
        "            return self.b + self.b_u[user_idx] + self.b_d + np.dot(self.P[user_idx], self.Q.T)\n",
        "        else:\n",
        "            return np.full(self.num_items, self.b)  # 평균 평점으로 채운 배열 반환\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        if 'R' in state:\n",
        "            del state['R']\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        self.__dict__.update(state)\n",
        "        self.R = None"
      ],
      "metadata": {
        "id": "QpXRk970GwXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비\n",
        "user_ids = ratings_df_filtered['userId'].unique()\n",
        "movie_ids = ratings_df_filtered['movieId'].unique()\n",
        "\n",
        "# 데이터 준비\n",
        "user_ids = ratings_df_filtered['userId'].unique()\n",
        "movie_ids = ratings_df_filtered['movieId'].unique()\n",
        "\n",
        "# 사용자 ID 140000 ratings_df_filtered에 포함되어 있는지 확인\n",
        "if 140000 not in user_ids:\n",
        "    print(\"User ID 140000 is not in ratings_df_filtered. Please check the filtering process.\")\n",
        "else:\n",
        "    user_map = {user_id: index for index, user_id in enumerate(user_ids)}\n",
        "    movie_map = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
        "\n",
        "    row_indices = ratings_df_filtered['userId'].map(user_map)\n",
        "    col_indices = ratings_df_filtered['movieId'].map(movie_map)\n",
        "    data = ratings_df_filtered['rating']\n",
        "\n",
        "    # coo_matrix 생성\n",
        "    sparse_mat = coo_matrix((data, (row_indices, col_indices)), shape=(len(user_ids), len(movie_ids)))\n",
        "\n",
        "    # user_id_map 확인\n",
        "    print(\"User ID 140000 in user_id_map:\", 140000 in user_map)  # user_map에서 확인\n",
        "    print(\"User ID 140000 mapped index:\", user_map.get(140000, \"Not found\"))  # user_map에서 인덱스 확인\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "hyper_params = {\n",
        "    'K': 50,\n",
        "    'alpha': 0.001,\n",
        "    'beta': 0.02,\n",
        "    'iterations': 50,\n",
        "    'verbose': True,\n",
        "    'batch_size': 512,\n",
        "    'early_stopping_rounds': 5,\n",
        "    'n_jobs': -1\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0_kW_bJNLaa",
        "outputId": "6393617f-94be-40ee-acc4-b744a23babe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User ID 140000 in user_id_map: True\n",
            "User ID 140000 mapped index: 1349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# 연도 추출 함수\n",
        "def extract_year(title):\n",
        "    match = re.search(r'\\((\\d{4})\\)', title)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "# 데이터 로드\n",
        "ratings_df = pd.read_csv('rating.csv')\n",
        "movies_df = pd.read_csv('movie.csv')\n",
        "\n",
        "# 연도 열 추가\n",
        "movies_df['year'] = movies_df['title'].apply(extract_year)\n",
        "\n",
        "# ratings_df와 movies_df 병합\n",
        "merged_df = pd.merge(ratings_df, movies_df, on='movieId')\n",
        "\n",
        "# 연도별 평점 수 집계\n",
        "yearly_ratings_count = merged_df['year'].value_counts().sort_index()\n",
        "\n",
        "# 오름차순으로 정렬된 연도별 평점 수 출력\n",
        "sorted_yearly_ratings_count = yearly_ratings_count.sort_values()\n",
        "print(\"Yearly Ratings Count (Sorted in Ascending Order):\")\n",
        "print(sorted_yearly_ratings_count.tail(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC_jRnCh951t",
        "outputId": "b4357cda-dfb9-45c6-ea84-8beb35106c01",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yearly Ratings Count (Sorted in Ascending Order):\n",
            "year\n",
            "1954.0      6180\n",
            "1959.0      6368\n",
            "1963.0      6556\n",
            "2013.0      6905\n",
            "1962.0      7071\n",
            "1967.0      7952\n",
            "1964.0      8550\n",
            "1972.0      8591\n",
            "1976.0      9438\n",
            "2012.0      9515\n",
            "1974.0      9994\n",
            "1968.0     10172\n",
            "1973.0     10627\n",
            "1978.0     11079\n",
            "1971.0     12316\n",
            "2011.0     12320\n",
            "1977.0     12434\n",
            "1975.0     14308\n",
            "2010.0     17150\n",
            "1979.0     17369\n",
            "1983.0     19123\n",
            "1981.0     19202\n",
            "1980.0     20926\n",
            "2009.0     22217\n",
            "1982.0     24180\n",
            "2008.0     26478\n",
            "1985.0     27671\n",
            "2007.0     31420\n",
            "1984.0     32761\n",
            "1987.0     34252\n",
            "1988.0     34448\n",
            "1986.0     34992\n",
            "2005.0     35053\n",
            "2006.0     35272\n",
            "1991.0     38805\n",
            "1989.0     45007\n",
            "1990.0     45315\n",
            "1992.0     46299\n",
            "2003.0     50180\n",
            "2004.0     52674\n",
            "2002.0     59974\n",
            "2001.0     66864\n",
            "2000.0     80153\n",
            "1998.0     81622\n",
            "1997.0     84595\n",
            "1993.0     91218\n",
            "1999.0    101123\n",
            "1996.0    110809\n",
            "1994.0    127022\n",
            "1995.0    148289\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "cf_model = CollaborativeFiltering(sparse_mat, hyper_params)\n",
        "\n",
        "print(\"Setting up test set...\")\n",
        "test_set = cf_model.set_test(ratings_test)\n",
        "print(\"Test set setup complete.\")\n",
        "\n",
        "print(f\"Initial memory usage: {get_memory_usage():.2f} MB\")\n",
        "\n",
        "def train_with_memory_management():\n",
        "    global cf_model, hyper_params\n",
        "    try:\n",
        "        result = cf_model.train()\n",
        "    except MemoryError:\n",
        "        print(\"MemoryError occurred during training. Trying to reduce memory usage...\")\n",
        "        del cf_model\n",
        "        hyper_params['K'] = max(5, hyper_params['K'] // 2)\n",
        "        hyper_params['batch_size'] *= 2\n",
        "        cf_model = CollaborativeFiltering(sparse_mat, hyper_params)\n",
        "        test_set = cf_model.set_test(ratings_test)\n",
        "        try:\n",
        "            result = cf_model.train()\n",
        "        except MemoryError:\n",
        "            print(\"MemoryError still occurring. Consider using a machine with more memory or further optimizing the code.\")\n",
        "            return None\n",
        "    return result\n",
        "\n",
        "result = train_with_memory_management()\n"
      ],
      "metadata": {
        "id": "zQ1rcSVchtlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21aa5cfd-4404-46a9-d8db-d9b2d62ef95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up test set...\n",
            "Test set setup complete.\n",
            "Initial memory usage: 923.14 MB\n",
            "Iteration : 10 ; Train RMSE = 0.8698 ; Test RMSE = 1.2083\n",
            "Iteration : 20 ; Train RMSE = 0.8587 ; Test RMSE = 1.2405\n",
            "Iteration : 30 ; Train RMSE = 0.8538 ; Test RMSE = 1.2556\n",
            "Iteration : 40 ; Train RMSE = 0.8490 ; Test RMSE = 1.2641\n",
            "Iteration : 50 ; Train RMSE = 0.8392 ; Test RMSE = 1.2689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if result is not None:\n",
        "    def save_model_data(cf_model, user_map, movie_map, movies_df, ratings_df, model_dir='/content/model_data'):\n",
        "      os.makedirs(model_dir, exist_ok=True)\n",
        "      model_path = os.path.join(model_dir, 'cf_model_v2.pkl')\n",
        "      data_to_save = {\n",
        "          'model': cf_model,\n",
        "          'user_map': user_map,\n",
        "          'movie_map': movie_map,\n",
        "          'movies_df': movies_df_filtered,\n",
        "          'ratings_df': ratings_df_filtered  # ratings_df 추가\n",
        "\n",
        "      }\n",
        "      joblib.dump(data_to_save, model_path)\n",
        "      print(f\"Model and data saved in {model_path}\")\n",
        "\n",
        "    # 모델 저장\n",
        "    save_model_data(cf_model, user_map, movie_map, movies_df_filtered, ratings_df_filtered)\n",
        "\n",
        "    print(f\"Final memory usage: {get_memory_usage():.2f} MB\")\n",
        "\n",
        "    # 모델 평가 및 분석\n",
        "    print(f\"movies_df의 영화 수: {len(movies_df_filtered)}\")\n",
        "    print(f\"모델의 영화 수: {len(cf_model.item_id_map)}\")\n",
        "\n",
        "    model_movie_ids = set(cf_model.item_id_map.keys())\n",
        "    df_movie_ids = set(movies_df_filtered['movieId'])\n",
        "\n",
        "    print(f\"공통 영화 ID 수: {len(model_movie_ids & df_movie_ids)}\")\n",
        "    print(f\"movies_df에만 있는 영화 ID 수: {len(df_movie_ids - model_movie_ids)}\")\n",
        "    print(f\"모델에만 있는 영화 ID 수: {len(model_movie_ids - df_movie_ids)}\")\n",
        "\n",
        "    mismatched_ids = list(df_movie_ids - model_movie_ids)[:5]\n",
        "    print(\"\\n불일치하는 영화 ID 예시:\")\n",
        "    for movie_id in mismatched_ids:\n",
        "        movie = movies_df_filtered[movies_df_filtered['movieId'] == movie_id].iloc[0]\n",
        "        print(f\"Movie ID: {movie_id}, Title: {movie['title']}\")\n",
        "\n",
        "    # # 사용자별 추천 영화 출력\n",
        "    # for user_id in [140000]:\n",
        "    #     user_predictions = cf_model.predict_for_user(user_id)\n",
        "    #     top_movie_indices = np.argsort(user_predictions)[::-1][:15]\n",
        "    #     top_movie_ids = [cf_model.idx_item_map[idx] for idx in top_movie_indices]\n",
        "    #     recommended_movies = movies_df_filtered[movies_df_filtered['movieId'].isin(top_movie_ids)]\n",
        "\n",
        "    #     print(f\"\\n사용자 {user_id}에 대한 추천 영화:\")\n",
        "    #     print(f\"예측된 영화 수: {len(user_predictions)}\")\n",
        "    #     print(f\"최소 예측 평점: {np.min(user_predictions):.2f}\")\n",
        "    #     print(f\"최대 예측 평점: {np.max(user_predictions):.2f}\")\n",
        "\n",
        "    #     print(\"\\n상위 10개 추천 영화:\")\n",
        "    #     for idx, movie in recommended_movies.iterrows():\n",
        "    #         movie_id = movie['movieId']\n",
        "    #         predicted_rating = user_predictions[cf_model.item_id_map[movie_id]]\n",
        "    #         print(f\"제목: {movie['title']}, 장르: {movie['genres']}, 예측 평점: {predicted_rating:.2f}\")\n",
        "\n",
        "    # 모델 성능 평가\n",
        "    train_rmse = cf_model.rmse()\n",
        "    test_rmse = cf_model.test_rmse()\n",
        "    print(f\"\\n최종 Train RMSE: {train_rmse:.4f}\")\n",
        "    print(f\"최종 Test RMSE: {test_rmse:.4f}\")\n",
        "else:\n",
        "    print(\"모델 학습에 실패했습니다. 메모리 문제를 해결하지 못했습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L8v43pwIgTD",
        "outputId": "ee6b9dc2-2ae7-4285-ff66-e78d7d9a17a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and data saved in /content/model_data/cf_model_v2.pkl\n",
            "Final memory usage: 1206.97 MB\n",
            "movies_df의 영화 수: 27280\n",
            "모델의 영화 수: 19100\n",
            "공통 영화 ID 수: 8337\n",
            "movies_df에만 있는 영화 ID 수: 18943\n",
            "모델에만 있는 영화 ID 수: 10763\n",
            "\n",
            "불일치하는 영화 ID 예시:\n",
            "Movie ID: 131072, Title: Jesus liebt mich (2012)\n",
            "Movie ID: 98304, Title: So Big! (1932)\n",
            "Movie ID: 131074, Title: Mount St. Elias (2009)\n",
            "Movie ID: 32770, Title: Brothers (Brødre) (2004)\n",
            "Movie ID: 131076, Title: Süperseks (2004)\n",
            "\n",
            "최종 Train RMSE: 0.8392\n",
            "최종 Test RMSE: 1.2689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_index = user_map[140000]\n",
        "\n",
        "# 사용자별 추천 영화 출력\n",
        "user_predictions = cf_model.predict_for_user(user_index)\n",
        "top_movie_indices = np.argsort(user_predictions)[::-1][:25]\n",
        "top_movie_ids = [cf_model.idx_item_map[idx] for idx in top_movie_indices]\n",
        "recommended_movies = movies_df_filtered[movies_df_filtered['movieId'].isin(top_movie_ids)]\n",
        "\n",
        "print(f\"\\n사용자 {140000}에 대한 추천 영화:\")\n",
        "print(f\"예측된 영화 수: {len(user_predictions)}\")\n",
        "print(f\"최소 예측 평점: {np.min(user_predictions):.2f}\")\n",
        "print(f\"최대 예측 평점: {np.max(user_predictions):.2f}\")\n",
        "\n",
        "print(\"\\n상위 10개 추천 영화:\")\n",
        "for idx, movie in recommended_movies.iterrows():\n",
        "    movie_id = movie['movieId']\n",
        "    predicted_rating = user_predictions[cf_model.item_id_map[movie_id]]\n",
        "    print(f\"제목: {movie['title']}, 장르: {movie['genres']}, 예측 평점: {predicted_rating:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKi6RLPPjrsW",
        "outputId": "2d34965a-0e8e-4c89-9bad-66940f46249e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "사용자 140000에 대한 추천 영화:\n",
            "예측된 영화 수: 19100\n",
            "최소 예측 평점: 1.57\n",
            "최대 예측 평점: 4.59\n",
            "\n",
            "상위 10개 추천 영화:\n",
            "제목: Four Rooms (1995), 장르: Comedy, 예측 평점: 4.48\n",
            "제목: Babe (1995), 장르: Children|Drama, 예측 평점: 4.48\n",
            "제목: Browning Version, The (1994), 장르: Drama, 예측 평점: 4.48\n",
            "제목: Song of the Little Road (Pather Panchali) (1955), 장르: Drama, 예측 평점: 4.48\n",
            "제목: Low Life (1994), 장르: Drama, 예측 평점: 4.54\n",
            "제목: Arrival, The (1996), 장르: Action|Sci-Fi|Thriller, 예측 평점: 4.59\n",
            "제목: Crow: City of Angels, The (1996), 장르: Action|Thriller, 예측 평점: 4.53\n",
            "제목: Ben-Hur (1959), 장르: Action|Adventure|Drama, 예측 평점: 4.51\n",
            "제목: Nenette and Boni (Nénette et Boni) (1996), 장르: Drama, 예측 평점: 4.47\n",
            "제목: Twisted (1996), 장르: Comedy|Drama, 예측 평점: 4.47\n",
            "제목: Henry Fool (1997), 장르: Comedy|Drama, 예측 평점: 4.48\n",
            "제목: Shaggy D.A., The (1976), 장르: Children|Comedy, 예측 평점: 4.47\n",
            "제목: Suburbans, The (1999), 장르: Drama, 예측 평점: 4.45\n",
            "제목: Kelly's Heroes (1970), 장르: Action|Comedy|War, 예측 평점: 4.49\n",
            "제목: Time Machine, The (1960), 장르: Action|Adventure|Sci-Fi, 예측 평점: 4.48\n",
            "제목: Magnificent Seven, The (1960), 장르: Adventure|Western, 예측 평점: 4.46\n",
            "제목: Grateful Dawg (2000), 장르: Documentary, 예측 평점: 4.46\n",
            "제목: Ali (2001), 장르: Drama, 예측 평점: 4.45\n",
            "제목: Spy Kids 2: The Island of Lost Dreams (2002), 장르: Adventure|Children, 예측 평점: 4.46\n",
            "제목: Shock Waves (1977), 장르: Horror, 예측 평점: 4.48\n",
            "제목: Alone in the Dark (1982), 장르: Horror, 예측 평점: 4.56\n",
            "제목: Bad Boys II (2003), 장르: Action|Comedy|Crime|Thriller, 예측 평점: 4.46\n",
            "제목: City Limits (1984), 장르: Action|Sci-Fi, 예측 평점: 4.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 ID 140000이 user_id_map에 매핑된 인덱스 확인\n",
        "user_id = 140000\n",
        "if user_id in user_map:\n",
        "    mapped_index = user_map[user_id]\n",
        "    print(f\"User ID {user_id} is mapped to index {mapped_index} in user_map.\")\n",
        "else:\n",
        "    print(f\"User ID {user_id} is not found in user_map.\")\n",
        "\n",
        "# COO Matrix의 row_indices에서 사용자 ID 140000의 인덱스 확인\n",
        "row_indices = ratings_df_filtered['userId'].map(user_map)\n",
        "print(f\"Row index for User ID {user_id}: {row_indices[ratings_df_filtered['userId'] == user_id].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPDDwFCSJQTz",
        "outputId": "f2f61c32-61ad-45f1-fce3-161602055768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User ID 140000 is mapped to index 1349 in user_map.\n",
            "Row index for User ID 140000: [1349]\n"
          ]
        }
      ]
    }
  ]
}